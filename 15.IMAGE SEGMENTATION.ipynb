{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1bb5f2a-ac94-4e51-b633-cfa796ce2d98",
   "metadata": {},
   "source": [
    "# IMAGE SEGMENTATION IN OPENCV\n",
    "\n",
    "## WHAT IS IMAGE SEGMENTATION?\n",
    "\n",
    "**image Segmentation** is the process of partitioning an image into multiple segments (set of pixels), with the goal of simplyfying or changing the representation of an image into something more meaningful and easier to analyze.  Segmentation can be used to locate and identify objects and boundaries (lines, curves, etc.) in images.\n",
    "\n",
    "\n",
    "## WHY IS IMAGE SEGMENTATION IMPORTANT?\n",
    "\n",
    "* **Simplification:** Reduces the complexity of an image while retaining its important structures.\n",
    "* **Analysis:** Facilities the analysis of objects by isolating them from the background.\n",
    "* **feature Extraction:** helps in extracting features needed for further processing tasks such as classification or recognition. \n",
    "* **Object Detection:** Enables the identification of different onbjects in a scene, which is crucial for many computer vision applications.\n",
    "\n",
    "## TYOES OF IMAGE SEGMENTATION:\n",
    "\n",
    " **1. Thresholding:**\n",
    "   * Converts grayscale images into binary images by applying a threshold value.\n",
    "   * Useful for separating objects from the background based on intensity.\n",
    "\n",
    " **2. Edge Detection:**\n",
    "   * Identifies boundaries within images using techniques such as the Canny edge detector.\n",
    "   * Segments images based on abrupt changes in intensity.\n",
    " \n",
    " **3. Region-Based Segmentation:**\n",
    "   * Groups nrighbouring pixels that have similar values, creating regions based on predefined criteria.\n",
    "   * Methods include Region Growing and Watershed Algorithm.\n",
    " \n",
    " **4. Clustering:**\n",
    "   * uses clustering algorithms (e.g, K-means, Mean Shift) to group similar pixels.\n",
    "   * Effective for segmenting images based on color or texture.\n",
    " \n",
    " **5. Deep Learning-Based Segmentation:**\n",
    "   * Utilizes neural networks (e.g, U-NEt, Mask R-CNN) to achieve high accuracy in segmenting comples images.\n",
    "   * Suitable for various applications including medical image aalysis.\n",
    "\n",
    "## REAL-TIME APPLICATIONS OF IMAGE SEGMENTATION\n",
    "\n",
    " **1. Medical Imaging:**\n",
    "   * Segmenting anatonomical structures (e.g, organs, tumours) from medical scans (MRI, CT) for diagnosis and tratment planning.\n",
    "\n",
    " **2. Autonomous Vehicles:**\n",
    "   * Identifying and segmenting road signs, pedestrians, and other vehicles in real-time for safe navigation.\n",
    "\n",
    " **3. Object Recognition:**\n",
    "   * Facilitating Object recognition in robotics and augmented reality by isolating objects fromtheir backgrounds.\n",
    "\n",
    " **4. Satellite Imagery:**\n",
    "   * Segmenting land use and land cover in remote sensing applcation for environmental monitoring.\n",
    "\n",
    " **5. Image Editing:**\n",
    "   * Enabling advanced editing techniques such as background removal and objects manipulation in graphic design.\n",
    "    \n",
    "## EXAMPLE OF IMAGE SEGMENTATION IN OPENCV\n",
    "\n",
    "Here is a simple example of image segmentation using thresholding and contours in OpenCV:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c293a12-045e-44fd-9147-04b76e7f8177",
   "metadata": {},
   "source": [
    "# WHAT ARE CONTOURS IN OPENCV?\n",
    "\n",
    "Contour are curves that connect all the continous points along a boundary with the same color or intensity.  In simpler terms, they represent the outlines or boundaries of objects in an image.  Contours are useful for shape analysis, object detection, and recognition in various computer vision applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07698ec0-a179-41da-b1fc-a606e17f358d",
   "metadata": {},
   "source": [
    "# IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34355863-b3a1-4c1c-9f2b-1bf001d5a1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684c092e-b94b-4126-a1e8-a8f62a96a770",
   "metadata": {},
   "source": [
    "# LOAD THE IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f6e2314-f2fd-4580-bd12-02c1e26bcee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv.imread('girl.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d87a63-4485-4a57-9cd7-9171f075ca11",
   "metadata": {},
   "source": [
    "# CONVERT TO GRAYSCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c51dfdc-f4f6-49c7-9527-d7be68cccce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv.cvtColor(image,cv.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26fbefb-75ed-488e-9068-d3374680d075",
   "metadata": {},
   "source": [
    "# APPLY BINARY THRESHOLDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f33e83fa-d194-49cd-a8d6-84e95c79d117",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, thresh = cv.threshold(gray, 127, 255, cv.THRESH_BINARY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89af2b80-6c5d-42e1-b0cf-78536d0307e2",
   "metadata": {},
   "source": [
    "# FIND CONTOURS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e95faf56-f1f1-4c5f-879c-581e94d3b834",
   "metadata": {},
   "outputs": [],
   "source": [
    "contours, _ = cv.findContours(thresh, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b139088-3e51-4bf5-a3f6-fb59dab01ca2",
   "metadata": {},
   "source": [
    "# DRAW CONTOURS ON THE ORIGINAL IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bafcd797-2ea7-4720-9ef1-4efc116edb0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[113, 124,  98],\n",
       "        [255,   0,   0],\n",
       "        [255,   0,   0],\n",
       "        ...,\n",
       "        [ 92,  97,  96],\n",
       "        [ 90,  95,  94],\n",
       "        [ 87,  92,  91]],\n",
       "\n",
       "       [[113, 124,  98],\n",
       "        [255,   0,   0],\n",
       "        [255,   0,   0],\n",
       "        ...,\n",
       "        [ 91,  96,  95],\n",
       "        [ 89,  94,  93],\n",
       "        [ 86,  91,  90]],\n",
       "\n",
       "       [[115, 125, 102],\n",
       "        [255,   0,   0],\n",
       "        [255,   0,   0],\n",
       "        ...,\n",
       "        [ 89,  94,  93],\n",
       "        [ 86,  91,  90],\n",
       "        [ 84,  89,  88]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 31,  35,  23],\n",
       "        [ 39,  43,  31],\n",
       "        [ 46,  50,  38],\n",
       "        ...,\n",
       "        [223, 221, 213],\n",
       "        [255,   0,   0],\n",
       "        [255,   0,   0]],\n",
       "\n",
       "       [[ 45,  49,  37],\n",
       "        [ 42,  46,  34],\n",
       "        [ 40,  44,  32],\n",
       "        ...,\n",
       "        [255,   0,   0],\n",
       "        [255,   0,   0],\n",
       "        [255,   0,   0]],\n",
       "\n",
       "       [[ 60,  64,  52],\n",
       "        [ 44,  48,  36],\n",
       "        [ 33,  37,  25],\n",
       "        ...,\n",
       "        [255,   0,   0],\n",
       "        [255,   0,   0],\n",
       "        [255,   0,   0]]], dtype=uint8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.drawContours(image, contours, -1, (255,0,0), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7406e5e-5774-428e-aeca-1ea28914a3ef",
   "metadata": {},
   "source": [
    "# DISPLAY RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dee49259-6108-4822-ab2b-60cca871a55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.imshow('Original Image', image)\n",
    "cv.imshow('Threshold Image', thresh)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d59ac8-1ae7-4e3f-bdcc-d9bb7bd90ad6",
   "metadata": {},
   "source": [
    "# **CANNY EDGE** \n",
    "\n",
    "## **HOW CANNY EDGE DETECTION WORKS**\n",
    "\n",
    "### **NOISE REDUCTION:**\n",
    "\n",
    "The algorithm first applies a Gaussian blur to tje image to reduce noise and improve edge detection. This step helps to avoid detecting false edges due to noise\n",
    "\n",
    "### **GRADIENT CALCULATION:**\n",
    "\n",
    "Is computes the gradient of the image intensity using techniques like the Sobel operator. This helps in identifying regions of the image where the intensity changes sharply, which are potential edges.\n",
    "\n",
    "### **NON-MAXIMUM SUPRESSION:**\n",
    "\n",
    "The algorithm thins the edges bysupressingnon-maximum pixels, ensuring that only the most significant edges remain.\n",
    "\n",
    "### **HYSTERSIS THESHOLDING:**\n",
    "\n",
    "Finally it uses the two thresholds to identify strong and weak edges. Strong edges are kept, and weak edges are retained only if they are connected to strong edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b361d9c7-03dd-4c3c-9bbd-fc705889594d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('girl.png')\n",
    "canny = cv.Canny(img,120,200)\n",
    "cv.imshow('image',img)\n",
    "cv.imshow('canny',canny)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b2b760-104f-4d14-81fa-9ab444fdb4dc",
   "metadata": {},
   "source": [
    "# USING CANNY AND CONTOURS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "39a98a1d-4478-4b49-8b48-456f93d547ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "while(True):\n",
    "    re, frame = cap.read()\n",
    "\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    blurred = cv.GaussianBlur(gray,(5,5),0)\n",
    "\n",
    "    edges = cv.Canny(blurred, 50, 150)\n",
    "\n",
    "    contours, _ = cv.findContours(edges, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    cv.drawContours(edges, contours, -1, (255,0,0),2)\n",
    "    cv.drawContours(frame, contours, -1, (255,0,0),2)\n",
    "\n",
    "    cv.imshow('frame', frame)\n",
    "    #cv.imshow('edges',edges)\n",
    "\n",
    "    if cv.waitKey(20) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98f3359-258c-4a14-9786-c4d892a0b657",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
